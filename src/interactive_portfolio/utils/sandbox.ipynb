{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6c5f603",
   "metadata": {},
   "source": [
    "## Tips to keep in mind\n",
    "\n",
    "- Prefer Struct-of-Arrays (SoA) over Array-of-Structs (AoS). Keep each attribute in its own contiguous NumPy array: pos, vel, mass, … not a list of Particle objects. This maximizes cache locality, vectorization, and Numba/JAX/CuPy performance.\n",
    "\n",
    "- Avoid Python objects in inner loops. Pure float32/float64 and int32 NumPy arrays; no lists of dicts, no per-particle dataclasses.\n",
    "\n",
    "- Dense, fixed-shape arrays. Ragged arrays and variable-length lists hurt vectorization and JIT.\n",
    "\n",
    "- Separate dynamic from static. Put evolving state (pos/vel) in one block, constants (mass/radius/type) in another so you can stream the hot data every step.\n",
    "\n",
    "- IDs vs indices. Use stable id (int) for external references, but store state in dense arrays addressed by dense index. Keep an id↔index mapping (“sparse set”) to enable O(1) add/remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11a4d442",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import numba as nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f50bc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ParticleSet:\n",
    "    # --- Fixed-size storage ---\n",
    "    capacity: int\n",
    "    dimensions: int = 3\n",
    "    dtype: np.dtype = np.float32\n",
    "\n",
    "    # --- arrays (allocated in __post_init__) ---\n",
    "    positions:  np.ndarray = None   # (capacity, dimensions)\n",
    "    velocities: np.ndarray = None   # (capacity, dimensions)\n",
    "    masses:     np.ndarray = None   # (capacity,)\n",
    "    radii:      np.ndarray = None   # (capacity,)\n",
    "\n",
    "    # --- bookkeeping ---\n",
    "    alive_mask:   np.ndarray = None # (capacity,), True for active rows in [0:size)\n",
    "    particle_ids: np.ndarray = None # (capacity,), int64 stable handles\n",
    "    id_to_index:  dict = None       # maps particle_id -> dense index\n",
    "\n",
    "    # --- active count (all active particles are stored in rows [0:size)) ---\n",
    "    size: int = 0\n",
    "    next_id: int = 0                # monotonically increasing ID source\n",
    "\n",
    "    def __post_init__(self):\n",
    "        N, D = self.capacity, self.dimensions\n",
    "        self.positions  = np.zeros((N, D), dtype=self.dtype)\n",
    "        self.velocities = np.zeros((N, D), dtype=self.dtype)\n",
    "        self.masses     = np.ones(N, dtype=self.dtype)\n",
    "        self.radii      = np.zeros(N, dtype=self.dtype)\n",
    "\n",
    "        self.alive_mask   = np.zeros(N, dtype=bool)\n",
    "        self.particle_ids = np.empty(N, dtype=np.int64)\n",
    "        self.id_to_index  = {}\n",
    "\n",
    "    # --- add / spawn (batch) ---\n",
    "    def add(self, positions, velocities, masses, radii):\n",
    "        \"\"\"\n",
    "        Add k particles in one call.\n",
    "        Returns: np.ndarray of particle_ids with shape (k,)\n",
    "        \"\"\"\n",
    "        k = positions.shape[0]\n",
    "        assert positions.shape  == (k, self.dimensions)\n",
    "        assert velocities.shape == (k, self.dimensions)\n",
    "        assert masses.shape     == (k,)\n",
    "        assert radii.shape      == (k,)\n",
    "        if self.size + k > self.capacity:\n",
    "            raise ValueError(\"Not enough capacity to add particles\")\n",
    "\n",
    "        start = self.size\n",
    "        end   = start + k\n",
    "\n",
    "        self.positions[start:end]  = positions\n",
    "        self.velocities[start:end] = velocities\n",
    "        self.masses[start:end]     = masses\n",
    "        self.radii[start:end]      = radii\n",
    "        self.alive_mask[start:end] = True\n",
    " \n",
    "        # --- assign stable, unique IDs ---\n",
    "        new_ids = np.arange(self.next_id, self.next_id + k, dtype=np.int64)\n",
    "        self.particle_ids[start:end] = new_ids\n",
    "        for row, pid in enumerate(new_ids, start=start):\n",
    "            self.id_to_index[int(pid)] = row\n",
    "        self.next_id += k\n",
    "\n",
    "        self.size = end\n",
    "        return new_ids\n",
    "\n",
    "    # --- remove (swap-remove keeps front dense) ---\n",
    "    def remove_by_index(self, index: int):\n",
    "        \"\"\"Remove particle at dense index `index` by swapping with the last active row.\"\"\"\n",
    "        last_active = self.size - 1\n",
    "        if index < 0 or index > last_active:\n",
    "            raise IndexError(\"Index out of range\")\n",
    "\n",
    "        removed_id = int(self.particle_ids[index])\n",
    "\n",
    "        if index != last_active:\n",
    "            # --- move last active particle into the hole ---\n",
    "            for arr in (self.positions, self.velocities, self.masses, self.radii,\n",
    "                        self.particle_ids, self.alive_mask):\n",
    "                arr[index], arr[last_active] = arr[last_active].copy(), arr[index].copy()\n",
    "            # --- fix mapping for the moved particle ---\n",
    "            moved_id = int(self.particle_ids[index])\n",
    "            self.id_to_index[moved_id] = index\n",
    "\n",
    "        # --- mark tail as inactive and drop mapping for removed particle ---\n",
    "        self.alive_mask[last_active] = False\n",
    "        self.id_to_index.pop(removed_id, None)\n",
    "        self.size -= 1\n",
    "\n",
    "    def remove_by_id(self, particle_id: int):\n",
    "        \"\"\"Remove a particle using its stable ID.\"\"\"\n",
    "        index = self.id_to_index.get(int(particle_id))\n",
    "        if index is None:\n",
    "            raise KeyError(\"Unknown particle_id\")\n",
    "        self.remove_by_index(index)\n",
    "    \n",
    "    # --- convenience views ---\n",
    "    def active_slice(self):\n",
    "        \"\"\"Slice covering all active rows (0..size-1).\"\"\"\n",
    "        return slice(0, self.size)\n",
    "\n",
    "    def active_arrays(self):\n",
    "        \"\"\"Views for kernels: only the active prefix.\"\"\"\n",
    "        s = self.active_slice()\n",
    "        return (self.positions[s], self.velocities[s], self.masses[s], self.radii[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de611aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- example usage ---\n",
    "test_set = ParticleSet(capacity=100_000, dimensions=2)\n",
    "\n",
    "# --- add 10 particles --- \n",
    "num_particles = 10\n",
    "ids = test_set.add(positions=np.random.randn(num_particles,2).astype(np.float32),\n",
    "                   velocities=np.zeros((num_particles,2), np.float32),\n",
    "                   masses=np.ones(num_particles, np.float32),\n",
    "                   radii=0.05*np.ones(num_particles, np.float32))\n",
    " \n",
    "# --- remove by id --- \n",
    "test_set.remove_by_id(int(ids[3]))\n",
    "\n",
    "# --- pass active views to a kernel --- \n",
    "positions, velocities, masses, radii = test_set.active_arrays()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41bbd3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
